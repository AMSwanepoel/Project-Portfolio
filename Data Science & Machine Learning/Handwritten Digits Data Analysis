{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "restricted-somalia",
   "metadata": {},
   "source": [
    "# Data Analysis: MNIST Dataset, handwritten digit recognition; A Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-stephen",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-oasis",
   "metadata": {},
   "source": [
    "This notebook will take a pedagogical approach, where we undergo direct comparison of formulation of a two-layer neural network from scratch, relative to a library assisted neural network such that the accuracies of each are comparible and contrastable. This project is motivated by theoretical comparisons and will not include optimisation of the raw two-layer NN (neural network) due to time constraints. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-section",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-welcome",
   "metadata": {},
   "source": [
    "The MNIST dataset (Source: http://yann.lecun.com/exdb/mnist/) is a canonical dataset that is well known amongst the machine learning community due to its robust dataset, the dataset itself is useful to individuals who seek to experiment with deep learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. \n",
    "\n",
    "The dataset itself is comprised of 60,000 training images and 10,000 testing images.The images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field. Each imagine contains 784 pixels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-trinity",
   "metadata": {},
   "source": [
    "### Brief mathematical introduction to Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-sleeve",
   "metadata": {},
   "source": [
    "The following will summise the mathematics briefly, and not divulge full rigor or proof (however for further reading please see Bishop, Pattern recognition and machine learning. Vol. 4. springer, 2006.); \n",
    "\n",
    "The most crude form of a neural network is known as a perceptron, developed by Frank Rosenblatt, consisting of n number of inputs, only one neuron, and one output, where n is the number of features of our dataset. The process of passing the data through the neural network is regarded as forward propagation and the forward propagation carried out in a perceptron can be disected as follows. \n",
    "\n",
    "Initially, for a given input, xᵢ, with associated weightings, wᵢ, one can sum all the multiplicative values. The weightings abstractly represent the strength of the connection between the neuron and the influence of that pathway with respect to its influence on a given output. If the weight w₁ has a higher value than the weight w₂, then the input x₁ will have a higher influence on the output than w₂.\n",
    "\n",
    "Then, \n",
    "\\begin{equation}\n",
    "\\sum = (x_1 x w_1) + (x_2 x w_2) + ... + (x_n x w_n)\n",
    "\\end{equation}\n",
    "The row vectors of the inputs and weights are x = [x₁, x₂, … , xₙ] and w =[w₁, w₂, … , wₙ] respectively and their dot product is given by,\n",
    "\n",
    "\\begin{equation}\n",
    "x \\cdot w = (x_1 x w_1) + (x_2 x w_2) + ... + (x_n x w_n) = \\sum\n",
    "\\end{equation}\n",
    "\n",
    "i.e. the summation of the weights and inputs is equivalent to the dot product of said variables.\n",
    "\n",
    "Following this, we introduce a bias such that the bias, b, \n",
    "\\begin{equation}\n",
    "z = x \\cdot w + b\n",
    "\\end{equation}\n",
    "\n",
    "Where z, is simply the dot product of our inputs and weightings, with the bias, b, factored. Bias, occasionally referenced as offset provides the utility to shift our later introduced activation function, to generate required output values. \n",
    "\n",
    "We are then required to pass the value of z, to a non-linear activation function, without this, the neural network would have linear parameters and would essentially operate as a linear regression.  Moreover, they have a significant impact on the learning speed of the neural network. Perceptrons have binary step function as their activation function. However, we shall use sigmoid for this explanation, whereas in application we will use a Rectified Linear Unit (ReLU).\n",
    "\n",
    "The sigmoid function is as follows, \n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y}=\\sigma (z) = \\frac{1}{1+e^{-z}}\n",
    "\\end{equation}\n",
    "where σ denotes the sigmoid activation function and the output we get after the forward prorogation is known as the predicted value ŷ.\n",
    "\n",
    "Then, we require a learning algorithm, where the algorithm itself can be split into backpropogation and optimisation. Backpropogation is simply defined as a a backward propogation of errors, where the algorithm computes the gradient of a loss function with respect to its weights. Moreover, with reference to our perceptron, backpropogation is computed as follows; \n",
    "\n",
    "We require an estimation of how far one is from a particular desired solution a loss function is implemented. Canonically mean squared error is often chosen as the loss function for regression problems and cross entropy for classification problems. We refer to a regression problem and its loss function i.e mean squared error, which is formulated as the difference of the squares of the actual, yᵢ, and predicted value, ŷᵢ .\n",
    "\n",
    "\\begin{equation}\n",
    "MSE = (y_i - \\hat{y_i})^2\n",
    "\\end{equation}\n",
    "\n",
    "The loss function implemented can be known as the cost function, \n",
    "\\begin{equation}\n",
    "C = 1/n \\sum_{i=1}^{n}(y_i - \\hat{y_i})^2\n",
    "\\end{equation}\n",
    "\n",
    "We then assertain how the cost function evolves with respect to the weights and bias via the partial derivative of the cost function with respect to the weighting. It follows that, \n",
    "\\begin{equation}\n",
    "\\frac{\\partial C}{\\partial w_i} = \\frac{\\partial C}{\\partial \\hat{y}} x \\frac{\\partial \\hat{y}}{\\partial z} x \\frac{\\partial z}{\\partial w_i}\n",
    "\\end{equation}\n",
    "as a result of the chain rule. \n",
    "\n",
    "\n",
    "The mathematical formulations of the example given below is as follows, \n",
    "**Forward propagation**\n",
    "\n",
    "$$Z^{[1]} = W^{[1]} X + b^{[1]}$$\n",
    "$$A^{[1]} = g_{\\text{ReLU}}(Z^{[1]}))$$\n",
    "$$Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}$$\n",
    "$$A^{[2]} = g_{\\text{softmax}}(Z^{[2]})$$\n",
    "\n",
    "**Backward propagation**\n",
    "\n",
    "$$dZ^{[2]} = A^{[2]} - Y$$\n",
    "$$dW^{[2]} = \\frac{1}{m} dZ^{[2]} A^{[1]T}$$\n",
    "$$dB^{[2]} = \\frac{1}{m} \\Sigma {dZ^{[2]}}$$\n",
    "$$dZ^{[1]} = W^{[2]T} dZ^{[2]} .* g^{[1]\\prime} (z^{[1]})$$\n",
    "$$dW^{[1]} = \\frac{1}{m} dZ^{[1]} A^{[0]T}$$\n",
    "$$dB^{[1]} = \\frac{1}{m} \\Sigma {dZ^{[1]}}$$\n",
    "\n",
    "**Parameter updates**\n",
    "\n",
    "$$W^{[2]} := W^{[2]} - \\alpha dW^{[2]}$$\n",
    "$$b^{[2]} := b^{[2]} - \\alpha db^{[2]}$$\n",
    "$$W^{[1]} := W^{[1]} - \\alpha dW^{[1]}$$\n",
    "$$b^{[1]} := b^{[1]} - \\alpha db^{[1]}$$\n",
    "\n",
    "The neural network will be comprised of a single hidden layer, an input layer and an output layer, the Input layer $a^{[0]}$ will have 784 units corresponding to the 784 pixels in each 28x28 input image. The hidden layer, $a^{[1]}$, is represented as 10 units modified by ReLU activation. The output layer $a^{[2]}$ will have 10 units corresponding to the ten digit classes with softmax activation. For more of a pedagogical understanding, one can include the variable shape for dimensional representations, such that,\n",
    "\n",
    "Forward propogation:\n",
    "\n",
    "- $A^{[0]} = X$: 784 x m\n",
    "- $Z^{[1]} \\sim A^{[1]}$: 10 x m\n",
    "- $W^{[1]}$: 10 x 784 (as $W^{[1]} A^{[0]} \\sim Z^{[1]}$)\n",
    "- $B^{[1]}$: 10 x 1\n",
    "- $Z^{[2]} \\sim A^{[2]}$: 10 x m\n",
    "- $W^{[1]}$: 10 x 10 (as $W^{[2]} A^{[1]} \\sim Z^{[2]}$)\n",
    "- $B^{[2]}$: 10 x 1\n",
    "\n",
    "Backward propogation: \n",
    "\n",
    "- $dZ^{[2]}$: 10 x m ($~A^{[2]}$)\n",
    "- $dW^{[2]}$: 10 x 10\n",
    "- $dB^{[2]}$: 10 x 1\n",
    "- $dZ^{[1]}$: 10 x m ($~A^{[1]}$)\n",
    "- $dW^{[1]}$: 10 x 10\n",
    "- $dB^{[1]}$: 10 x 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-sapphire",
   "metadata": {},
   "source": [
    "# Two Layer Neural Network (Scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "angry-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "operational-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\alexs\\GitHubRepo_PersonalProjects\\Kaggle\\MNIST\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "organizational-polish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "referenced-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversion of pandas dataframe to numpy array\n",
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data) # shuffle before splitting into dev and training sets to avoid overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "organized-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dev = data[0:1000].T\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:n]\n",
    "X_dev = X_dev / 255.\n",
    "\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255.\n",
    "_,m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "declared-broad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 5, 3, ..., 3, 0, 8], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "undefined-mixer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "creative-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter initialisation\n",
    "#Subtracting 0.5 to offset values between -0.5 and 0.5 \n",
    "def init_params():\n",
    "    W1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10, 1) - 0.5\n",
    "    W2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def softmax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A\n",
    "    \n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2)\n",
    "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1    \n",
    "    W2 = W2 - alpha * dW2  \n",
    "    b2 = b2 - alpha * db2    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "satisfactory-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "twelve-ethernet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[9 3 9 ... 5 2 9] [2 5 3 ... 3 0 8]\n",
      "0.08307317073170732\n",
      "Iteration:  10\n",
      "[9 4 9 ... 4 2 9] [2 5 3 ... 3 0 8]\n",
      "0.13817073170731708\n",
      "Iteration:  20\n",
      "[9 4 9 ... 4 0 9] [2 5 3 ... 3 0 8]\n",
      "0.20758536585365853\n",
      "Iteration:  30\n",
      "[9 4 9 ... 4 0 9] [2 5 3 ... 3 0 8]\n",
      "0.23680487804878048\n",
      "Iteration:  40\n",
      "[9 4 9 ... 4 0 9] [2 5 3 ... 3 0 8]\n",
      "0.26102439024390245\n",
      "Iteration:  50\n",
      "[9 3 9 ... 4 0 9] [2 5 3 ... 3 0 8]\n",
      "0.31514634146341464\n",
      "Iteration:  60\n",
      "[9 3 9 ... 8 0 9] [2 5 3 ... 3 0 8]\n",
      "0.36653658536585365\n",
      "Iteration:  70\n",
      "[9 3 9 ... 8 0 9] [2 5 3 ... 3 0 8]\n",
      "0.4027804878048781\n",
      "Iteration:  80\n",
      "[2 3 9 ... 8 0 9] [2 5 3 ... 3 0 8]\n",
      "0.4438780487804878\n",
      "Iteration:  90\n",
      "[2 3 7 ... 8 0 9] [2 5 3 ... 3 0 8]\n",
      "0.49121951219512194\n",
      "Iteration:  100\n",
      "[2 3 7 ... 8 0 9] [2 5 3 ... 3 0 8]\n",
      "0.5384878048780488\n",
      "Iteration:  110\n",
      "[2 3 7 ... 8 0 9] [2 5 3 ... 3 0 8]\n",
      "0.5767560975609756\n",
      "Iteration:  120\n",
      "[2 3 7 ... 8 0 9] [2 5 3 ... 3 0 8]\n",
      "0.6062439024390244\n",
      "Iteration:  130\n",
      "[2 6 7 ... 8 0 9] [2 5 3 ... 3 0 8]\n",
      "0.630780487804878\n",
      "Iteration:  140\n",
      "[2 6 7 ... 8 0 9] [2 5 3 ... 3 0 8]\n",
      "0.652219512195122\n",
      "Iteration:  150\n",
      "[2 6 7 ... 8 0 9] [2 5 3 ... 3 0 8]\n",
      "0.6717317073170732\n",
      "Iteration:  160\n",
      "[2 6 7 ... 8 0 4] [2 5 3 ... 3 0 8]\n",
      "0.6888536585365853\n",
      "Iteration:  170\n",
      "[2 6 7 ... 8 0 4] [2 5 3 ... 3 0 8]\n",
      "0.7012926829268292\n",
      "Iteration:  180\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.7137073170731707\n",
      "Iteration:  190\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.7255853658536585\n",
      "Iteration:  200\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.7351951219512195\n",
      "Iteration:  210\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.7439756097560976\n",
      "Iteration:  220\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.7524146341463415\n",
      "Iteration:  230\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.7603658536585366\n",
      "Iteration:  240\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.7677317073170732\n",
      "Iteration:  250\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.7742682926829269\n",
      "Iteration:  260\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.7794878048780488\n",
      "Iteration:  270\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.7844146341463415\n",
      "Iteration:  280\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.7897560975609756\n",
      "Iteration:  290\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.7945609756097561\n",
      "Iteration:  300\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.7989268292682927\n",
      "Iteration:  310\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8025121951219513\n",
      "Iteration:  320\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8062682926829269\n",
      "Iteration:  330\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8098048780487805\n",
      "Iteration:  340\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8130243902439024\n",
      "Iteration:  350\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.816170731707317\n",
      "Iteration:  360\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8186341463414634\n",
      "Iteration:  370\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8215853658536585\n",
      "Iteration:  380\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8239268292682926\n",
      "Iteration:  390\n",
      "[2 6 7 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8261219512195122\n",
      "Iteration:  400\n",
      "[2 6 3 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8280243902439024\n",
      "Iteration:  410\n",
      "[2 6 3 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8303414634146341\n",
      "Iteration:  420\n",
      "[2 6 3 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.832170731707317\n",
      "Iteration:  430\n",
      "[2 6 3 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8338536585365853\n",
      "Iteration:  440\n",
      "[2 6 3 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8356585365853658\n",
      "Iteration:  450\n",
      "[2 6 3 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8374634146341463\n",
      "Iteration:  460\n",
      "[2 6 3 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8396829268292683\n",
      "Iteration:  470\n",
      "[2 6 3 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8412439024390244\n",
      "Iteration:  480\n",
      "[2 6 3 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8426341463414634\n",
      "Iteration:  490\n",
      "[2 6 3 ... 8 0 8] [2 5 3 ... 3 0 8]\n",
      "0.8442926829268292\n"
     ]
    }
   ],
   "source": [
    "#Training \n",
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-record",
   "metadata": {},
   "source": [
    "**Model results**\n",
    "\n",
    "Note: Model produces an approximate 84% accuracy on the training set, however it should be commented due to the stochastic nature of the algorithm the results may vary slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-oxygen",
   "metadata": {},
   "source": [
    "### Prediction Testing the model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "distant-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "crucial-simpson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [2]\n",
      "Label:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [6]\n",
      "Label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [3]\n",
      "Label:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [2]\n",
      "Label:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(0, W1, b1, W2, b2)\n",
    "test_prediction(1, W1, b1, W2, b2)\n",
    "test_prediction(2, W1, b1, W2, b2)\n",
    "test_prediction(3, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-subscription",
   "metadata": {},
   "source": [
    "**Note**: Anecdotally we already observe a single error in graph 2, given an input of a 5, the algorithm has labelled it corresponding to the digit 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-poster",
   "metadata": {},
   "source": [
    "We seek to run the algorithm on the dev set, such that the performance of the algorithm can be qualitatively shown where the algorithm itself has had no training on the sets given images, effectively rendering the dev dataset as a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fresh-retreat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 9 5 4 4 8 1 7 5 4 0 5 2 8 6 6 3 1 2 2 4 7 9 9 9 7 1 5 8 6 4 9 0 4 3 7 0\n",
      " 7 0 9 3 7 6 3 6 4 6 4 3 6 5 8 8 5 4 4 6 6 2 0 1 9 1 0 7 8 0 8 1 0 7 3 1 3\n",
      " 8 2 5 2 1 4 6 6 6 8 7 6 1 4 8 4 2 7 2 8 5 7 0 5 0 7 8 7 1 9 1 0 8 3 5 8 8\n",
      " 9 0 9 6 5 1 7 1 9 2 7 0 6 8 6 4 6 7 5 6 3 2 3 2 3 7 7 1 2 4 4 4 6 1 9 7 7\n",
      " 4 9 4 8 1 6 1 7 8 6 0 0 3 7 2 3 8 1 5 3 7 9 0 3 8 1 8 8 5 3 1 6 6 0 7 1 4\n",
      " 1 7 9 7 5 3 4 1 7 7 3 2 9 2 6 7 9 9 1 1 2 1 9 7 1 3 9 1 6 1 9 1 8 9 3 8 1\n",
      " 9 0 8 1 2 3 4 9 5 6 0 9 6 7 4 0 5 6 2 5 1 1 2 9 5 4 0 7 2 8 7 1 5 3 9 1 4\n",
      " 8 9 9 7 7 5 7 0 3 0 5 7 4 1 9 6 8 1 4 4 3 7 9 7 8 9 6 9 7 9 3 8 7 6 7 8 1\n",
      " 8 8 8 9 5 8 8 1 8 4 8 6 2 5 6 1 9 0 4 0 2 0 3 8 3 6 7 4 8 4 2 9 7 1 6 6 2\n",
      " 5 2 3 7 4 1 9 7 3 1 4 2 6 1 5 1 9 5 7 9 3 9 1 3 0 8 1 0 0 1 5 6 2 5 5 6 3\n",
      " 8 3 4 9 5 9 3 3 9 3 9 4 1 9 7 7 1 2 9 8 0 3 8 5 8 1 9 5 5 1 1 9 2 8 0 7 6\n",
      " 0 5 7 5 3 5 5 0 4 4 4 5 1 3 8 9 9 3 0 5 9 8 9 8 8 1 1 5 5 0 4 9 9 3 3 4 6\n",
      " 9 6 7 3 1 6 2 4 0 5 5 8 7 0 1 0 2 3 1 6 0 6 0 2 1 4 3 2 9 0 9 7 8 6 9 8 3\n",
      " 2 7 9 9 8 3 9 4 7 0 4 4 6 4 0 8 6 7 3 6 8 6 0 4 1 6 5 4 1 8 8 5 6 5 9 5 9\n",
      " 3 0 6 3 8 8 1 0 9 4 6 9 8 2 0 9 1 4 6 5 8 2 8 4 4 9 5 8 8 7 2 1 1 2 4 8 4\n",
      " 2 4 8 4 8 9 0 5 4 5 4 4 3 6 7 0 7 1 9 9 3 8 8 4 8 6 2 8 2 0 7 3 8 4 7 7 0\n",
      " 9 0 1 2 6 5 4 1 0 6 3 9 6 8 3 9 6 5 0 3 9 2 9 0 9 2 1 5 4 4 2 2 2 3 2 8 3\n",
      " 1 1 2 0 0 3 8 7 3 7 9 1 7 1 3 1 6 1 1 7 7 7 9 3 9 9 5 1 1 9 9 6 0 0 3 4 4\n",
      " 3 3 3 9 1 1 0 7 3 9 8 9 5 9 4 1 3 2 1 9 8 5 9 0 8 0 4 8 4 2 6 9 4 9 1 1 7\n",
      " 5 1 2 9 7 2 6 2 1 3 1 5 3 1 3 6 3 5 3 0 4 1 8 1 8 9 9 9 0 8 1 8 4 3 6 1 9\n",
      " 0 3 0 6 2 9 4 0 0 3 2 5 7 1 3 9 1 6 1 5 3 6 3 8 9 2 4 2 9 7 3 9 9 4 6 7 4\n",
      " 1 0 1 6 3 1 7 7 7 7 3 6 0 9 8 4 2 9 6 0 7 1 4 9 0 2 7 4 7 3 7 3 4 6 1 0 1\n",
      " 9 0 5 3 7 3 0 2 0 9 3 4 9 6 7 4 2 7 8 2 0 5 2 0 3 2 5 8 1 1 0 4 1 6 4 9 3\n",
      " 6 8 2 3 2 0 5 0 6 4 0 6 0 4 7 3 5 7 9 7 2 7 5 2 5 6 3 7 6 3 8 6 5 9 4 1 2\n",
      " 0 8 3 4 5 9 3 4 5 6 8 0 7 6 5 1 9 4 9 1 7 9 1 3 9 4 7 7 9 6 0 0 2 6 0 7 2\n",
      " 3 2 4 1 8 3 9 4 9 3 7 9 6 9 7 3 2 3 3 3 2 1 2 6 1 6 6 9 4 0 4 4 7 1 9 1 2\n",
      " 3 3 6 4 7 3 7 1 3 9 6 8 4 3 9 9 1 7 6 7 5 9 7 4 6 4 2 8 1 9 8 7 8 1 1 2 2\n",
      " 2] [2 9 3 4 4 8 1 7 3 4 0 5 2 8 6 6 3 1 2 2 9 7 9 4 9 7 1 5 5 6 4 9 2 4 8 7 0\n",
      " 7 0 9 3 9 6 1 6 4 6 4 3 6 5 8 4 8 2 4 6 4 2 0 1 4 1 0 7 3 0 8 1 0 7 2 1 3\n",
      " 8 2 5 2 1 4 6 6 6 8 7 6 1 4 8 4 2 7 2 7 5 7 0 5 0 7 8 7 1 9 1 0 8 3 5 8 8\n",
      " 9 0 9 6 5 1 7 1 9 2 7 0 6 8 6 4 5 7 5 6 3 2 5 2 3 9 9 1 2 4 4 4 6 2 9 7 7\n",
      " 4 9 4 5 1 6 1 7 8 6 0 0 3 7 2 5 8 1 5 3 7 8 0 8 8 1 8 2 5 3 1 6 6 0 2 1 4\n",
      " 1 7 3 7 5 3 4 7 7 7 3 2 9 2 6 7 9 9 1 1 2 1 9 7 1 3 4 1 6 1 9 1 8 8 3 8 1\n",
      " 9 0 5 1 2 3 4 9 1 4 0 9 6 7 4 0 5 6 2 5 1 1 2 7 5 2 0 9 2 8 9 1 1 2 5 1 4\n",
      " 9 4 7 3 7 5 7 7 5 0 5 7 4 1 9 6 8 1 4 4 3 7 9 7 8 9 6 7 7 9 5 8 7 6 7 8 1\n",
      " 8 8 2 4 5 8 8 1 8 4 8 6 2 5 6 1 9 0 9 0 2 0 3 8 3 6 7 6 8 4 2 3 7 1 6 6 2\n",
      " 5 2 3 7 4 5 9 7 8 6 4 6 2 1 5 1 9 5 7 7 3 9 1 3 0 5 1 2 0 1 5 4 2 3 3 2 3\n",
      " 8 3 4 9 5 7 3 8 9 3 7 4 1 9 7 7 1 2 9 8 0 3 8 5 8 1 9 0 9 1 2 9 2 8 0 7 6\n",
      " 0 5 7 5 3 5 5 0 4 4 4 5 1 3 8 9 4 3 0 5 9 8 9 8 8 1 1 0 1 0 9 9 9 5 3 4 6\n",
      " 9 6 2 3 1 6 2 4 2 5 5 8 7 0 1 2 2 3 1 6 0 6 0 2 1 4 3 2 9 0 7 7 8 5 4 8 3\n",
      " 2 7 9 9 8 5 9 4 7 0 4 9 6 4 0 8 6 7 3 6 9 6 0 9 1 6 1 4 1 9 8 5 6 5 4 5 9\n",
      " 5 0 6 3 8 8 1 0 7 4 6 9 2 2 0 9 9 4 5 5 7 4 8 4 4 3 5 8 9 7 2 1 1 2 9 8 4\n",
      " 2 4 8 4 2 9 0 5 4 5 4 9 9 6 7 0 7 1 9 9 3 8 8 4 8 6 2 8 8 0 7 8 8 4 7 7 0\n",
      " 9 0 1 2 6 5 4 1 0 6 3 8 6 8 8 9 6 5 0 3 9 7 9 0 9 2 1 8 4 9 5 5 2 3 7 8 5\n",
      " 1 1 2 0 7 3 1 7 3 7 9 1 7 1 3 9 5 1 1 7 7 7 4 3 9 9 5 1 1 9 9 6 0 0 3 4 4\n",
      " 3 8 3 9 1 1 0 7 3 9 8 9 8 9 4 1 3 2 1 9 8 5 8 0 8 0 4 8 4 2 6 7 4 9 1 1 7\n",
      " 5 7 2 4 7 2 6 2 1 3 1 5 3 1 3 6 3 5 0 0 4 1 8 1 8 9 9 9 0 8 1 2 4 5 6 1 9\n",
      " 0 3 0 6 2 9 4 0 5 3 7 5 7 1 3 9 1 6 1 3 3 6 3 8 7 2 4 2 2 9 3 9 9 4 6 7 9\n",
      " 1 0 1 6 3 1 7 7 7 7 3 6 0 9 8 4 2 9 6 0 7 1 4 9 0 2 7 4 7 3 7 3 4 6 1 0 1\n",
      " 5 0 5 3 7 5 0 2 0 9 3 4 9 6 7 4 2 7 5 2 0 3 2 0 3 2 5 8 1 1 0 4 1 5 4 9 3\n",
      " 6 1 2 0 2 0 5 0 6 4 0 6 0 4 7 8 5 7 9 7 2 7 5 2 5 6 5 7 6 3 8 6 5 7 4 1 2\n",
      " 0 8 3 4 5 5 8 4 5 6 8 2 7 6 5 1 9 4 9 1 9 9 1 3 9 4 7 7 4 6 0 0 2 6 0 7 2\n",
      " 3 2 4 1 8 3 9 4 9 5 7 4 2 7 7 1 2 2 3 3 2 1 2 6 8 6 6 9 9 0 4 4 7 1 9 1 2\n",
      " 3 3 6 4 9 0 7 1 3 9 6 8 4 1 7 7 1 7 6 7 5 9 7 8 6 4 2 5 1 4 8 7 8 1 1 9 2\n",
      " 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.832"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_predictions = make_predictions(X_dev, W1, b1, W2, b2)\n",
    "get_accuracy(dev_predictions, Y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-delhi",
   "metadata": {},
   "source": [
    "**Model results**\n",
    "\n",
    "Note: Model produces an approximate 83% accuracy on the dev set, considering zero optimisation or training, the result is remarkable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-camel",
   "metadata": {},
   "source": [
    "# Tensorflow Library-assisted Neural Network Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-range",
   "metadata": {},
   "source": [
    "For brevity, we will not dissect or discuss any mathematical implementations, as we feel the fundamental procedure is briefly covered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "helpful-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "minute-fellowship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Loading training data directly from Tensorflow libaries, data is preprocessed and split into test and train segments\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "geological-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data to a scaling of length between [0,1]\n",
    "X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "apparent-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network Architecture\n",
    "#One flattened input layer\n",
    "#Two hidden layers as opposed to the original single hidden layer, may introduce discrepency in results\n",
    "#Single output layer for digits in the range [0,10]\n",
    "\n",
    "#Note: ReLU and softmax implemented, hence no rigorous explanation for pedagogy. \n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(units=10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-latest",
   "metadata": {},
   "source": [
    "Adam is an optimisation algorithm that can be used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data. for more information on the Adam optimisation algorithm see: https://arxiv.org/abs/1412.6980\n",
    "\n",
    "However, Adam can be considered to be a subsitute optimization algorithm for stochastic gradient descent for training deep learning models such that the best properties of the AdaGrad and RMSProp algorithms are instantiated and combined to provide an optimization algorithm that can handle sparse gradients on noisy problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efficient-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimisation and Compilation\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "furnished-demand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 1s 513us/step - loss: 0.2579 - accuracy: 0.9239\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 505us/step - loss: 0.1045 - accuracy: 0.9679\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 507us/step - loss: 0.0716 - accuracy: 0.9780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x269f07f75e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(X_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-rubber",
   "metadata": {},
   "source": [
    "**note**: Anecdotally we already see a vastly improved accuracy and loss, this is most likely due to optimised algorithms, training algorithms, and an extra hidden neural layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "positive-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 357us/step - loss: 0.0923 - accuracy: 0.9717\n",
      "0.09229560196399689\n",
      "0.9717000126838684\n"
     ]
    }
   ],
   "source": [
    "#Prediction Evaluation\n",
    "#Variables: val_loss = Predicted Value Loss, val_acc = Predicted Value Accuracy\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test)\n",
    "print(val_loss)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "outer-acrylic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alexs\\anaconda3\\envs\\RPythonEnv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\alexs\\anaconda3\\envs\\RPythonEnv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: MNIST_handwritten_numbers.model\\assets\n"
     ]
    }
   ],
   "source": [
    "#Keras model save feature to save model for later use, re-training not required\n",
    "model.save('MNIST_handwritten_numbers.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading\n",
    "#For future use, comment out the following code: any model.( ) code, for this project, lines between \n",
    "#model = tf.keras.models.Sequential() and model.fit(X_train, y_train, epochs=3)\n",
    "#model = tf.keras.models.load_model('MNIST_handwritten_numbers.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-mirror",
   "metadata": {},
   "source": [
    "### Prediction Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-religion",
   "metadata": {},
   "source": [
    "As an exercise, we seek to produce unique handwritten digits, procured to ones own directory consisting of 10 unique images. Proceeding, we format an image canvas such that images are grayscale 28x28 pixel image as specificed by the MNIST white paper. with assistance of a random number generator in the subset [0,10], we select a number to be hand-drawn onto the canvas. Following, we seek to apply the model trained previously to our unique dataset, to qualitatively assess the predictive strength of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "therapeutic-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_number = 1\n",
    "while os.path.isfile('SelfDrawn/digit{}.png'.format(image_number)):\n",
    "    try:\n",
    "        img = cv2.imread('SelfDrawn/digit{}.png'.format(image_number))[:,:,0]\n",
    "        img = np.invert(np.array([img]))\n",
    "        prediction = model.predict(img)\n",
    "        print(\"The number is probably a {}\".format(np.argmax(prediction)))\n",
    "        plt.imshow(img[0], cmap=plt.cm.binary)\n",
    "        plt.show()\n",
    "        image_number += 1\n",
    "    except:\n",
    "        print(\"Error reading image! Proceeding with next image...\")\n",
    "        image_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-silly",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-chamber",
   "metadata": {},
   "source": [
    "The two-layer neural network itself provided a succinct pedagogical approach to implementing the mathematical framework, moreover it allowed for a formulation of a more general approach to construction of machine learning algorithms and would serve as an adequate benchmark. The TensorFlow implementation was constructed to target a specific dataset and algorithmic approach, and provides a highly precise, however narrow algorithm that performs exceptionally well on a given example for this particular dataset. \n",
    "\n",
    "With respect to the accuracy of the models, the TensorFlow neural network outperformed the natural formulation substantially. Speculatively, this may be due to the additional hidden layer previously noted. Moreover, the TensorFlow model itself has intrinsicly optimised tools, that are programmed to satisfy high performance caps. The application of the Adam optimisation algorithm is also a significant factor as to the performance.\n",
    "\n",
    "The naturally formed two layer neural network however may perform significantly better upon optimisation or addition of an increased number of hidden layers. Further research exploration may include implementation of machineries such as normalisation, gradient descent with momentum, root-mean-square propogation or a convolutional neural network architecture.\n",
    "\n",
    "With respect to purpose, the Tensorflow model provides a high-level, swift approach to solving industrious machine learning problems, however for a deep comprehension of the underlying mechanics, the latter approach is not recommended without rigorous proof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-salad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
